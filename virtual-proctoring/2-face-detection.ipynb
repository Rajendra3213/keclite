{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection using Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [face detection API](https://docs.aws.amazon.com/rekognition/latest/dg/faces.html) in Amazon Rekognition to identify faces.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize dependencies\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "import time\n",
    "\n",
    "# Initialize clients\n",
    "REGION = boto3.session.Session().region_name or 'us-east-1'\n",
    "rekognition = boto3.client('rekognition', REGION)\n",
    "s3 = boto3.client('s3', REGION)\n",
    "\n",
    "bucket_name = 'test-images-891377001208'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect faces in image\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://test-images-891377001208.s3.amazonaws.com/looking_at_screen.jpg?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=2uSI%2FrdjshUKn12T98lWwzprjZ8%3D&Expires=1734030059\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show image\n",
    "image_name = \"looking_at_screen.jpg\"\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': image_name})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to detect faces in the image\n",
    "\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/faces-detect-images.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_faces_response = rekognition.detect_faces(\n",
    "    Attributes=['ALL'],\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': image_name,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see faces, detected attributes, confidence score and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FaceDetails': [{'BoundingBox': {'Width': 0.1543322205543518,\n",
       "    'Height': 0.38393434882164,\n",
       "    'Left': 0.44668450951576233,\n",
       "    'Top': 0.20054830610752106},\n",
       "   'AgeRange': {'Low': 30, 'High': 38},\n",
       "   'Smile': {'Value': False, 'Confidence': 99.94497680664062},\n",
       "   'Eyeglasses': {'Value': False, 'Confidence': 99.84290313720703},\n",
       "   'Sunglasses': {'Value': False, 'Confidence': 99.98878479003906},\n",
       "   'Gender': {'Value': 'Male', 'Confidence': 99.98247528076172},\n",
       "   'Beard': {'Value': True, 'Confidence': 99.8033447265625},\n",
       "   'Mustache': {'Value': True, 'Confidence': 64.8669204711914},\n",
       "   'EyesOpen': {'Value': True, 'Confidence': 97.28457641601562},\n",
       "   'MouthOpen': {'Value': False, 'Confidence': 99.2823257446289},\n",
       "   'Emotions': [{'Type': 'CALM', 'Confidence': 83.06396484375},\n",
       "    {'Type': 'SAD', 'Confidence': 7.379150390625},\n",
       "    {'Type': 'ANGRY', 'Confidence': 3.6956787109375},\n",
       "    {'Type': 'CONFUSED', 'Confidence': 1.1240642070770264},\n",
       "    {'Type': 'DISGUSTED', 'Confidence': 0.08096694946289062},\n",
       "    {'Type': 'SURPRISED', 'Confidence': 0.006884336471557617},\n",
       "    {'Type': 'HAPPY', 'Confidence': 0.002304712776094675},\n",
       "    {'Type': 'FEAR', 'Confidence': 0.0015944242477416992}],\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.4895631968975067,\n",
       "     'Y': 0.35889360308647156},\n",
       "    {'Type': 'eyeRight', 'X': 0.5552297830581665, 'Y': 0.3527182638645172},\n",
       "    {'Type': 'mouthLeft', 'X': 0.49813297390937805, 'Y': 0.48312491178512573},\n",
       "    {'Type': 'mouthRight', 'X': 0.5526813268661499, 'Y': 0.47797098755836487},\n",
       "    {'Type': 'nose', 'X': 0.5225225687026978, 'Y': 0.41206860542297363},\n",
       "    {'Type': 'leftEyeBrowLeft',\n",
       "     'X': 0.464642196893692,\n",
       "     'Y': 0.33519062399864197},\n",
       "    {'Type': 'leftEyeBrowRight',\n",
       "     'X': 0.5016624331474304,\n",
       "     'Y': 0.3165019750595093},\n",
       "    {'Type': 'leftEyeBrowUp',\n",
       "     'X': 0.4826718866825104,\n",
       "     'Y': 0.3135444223880768},\n",
       "    {'Type': 'rightEyeBrowLeft',\n",
       "     'X': 0.5393453240394592,\n",
       "     'Y': 0.3129364252090454},\n",
       "    {'Type': 'rightEyeBrowRight',\n",
       "     'X': 0.5789266228675842,\n",
       "     'Y': 0.3244330883026123},\n",
       "    {'Type': 'rightEyeBrowUp',\n",
       "     'X': 0.5585489273071289,\n",
       "     'Y': 0.3064020276069641},\n",
       "    {'Type': 'leftEyeLeft', 'X': 0.47796499729156494, 'Y': 0.3605530261993408},\n",
       "    {'Type': 'leftEyeRight',\n",
       "     'X': 0.5024904012680054,\n",
       "     'Y': 0.35865846276283264},\n",
       "    {'Type': 'leftEyeUp', 'X': 0.4890713691711426, 'Y': 0.3519791066646576},\n",
       "    {'Type': 'leftEyeDown', 'X': 0.48992520570755005, 'Y': 0.3641491234302521},\n",
       "    {'Type': 'rightEyeLeft', 'X': 0.5421649217605591, 'Y': 0.354933500289917},\n",
       "    {'Type': 'rightEyeRight',\n",
       "     'X': 0.5669411420822144,\n",
       "     'Y': 0.3522023558616638},\n",
       "    {'Type': 'rightEyeUp', 'X': 0.5550197958946228, 'Y': 0.3457764983177185},\n",
       "    {'Type': 'rightEyeDown', 'X': 0.5549371838569641, 'Y': 0.3580429255962372},\n",
       "    {'Type': 'noseLeft', 'X': 0.5113095641136169, 'Y': 0.4327964186668396},\n",
       "    {'Type': 'noseRight', 'X': 0.5356024503707886, 'Y': 0.4305402338504791},\n",
       "    {'Type': 'mouthUp', 'X': 0.5240858793258667, 'Y': 0.46041956543922424},\n",
       "    {'Type': 'mouthDown', 'X': 0.5252264142036438, 'Y': 0.4992482364177704},\n",
       "    {'Type': 'leftPupil', 'X': 0.4895631968975067, 'Y': 0.35889360308647156},\n",
       "    {'Type': 'rightPupil', 'X': 0.5552297830581665, 'Y': 0.3527182638645172},\n",
       "    {'Type': 'upperJawlineLeft',\n",
       "     'X': 0.45245301723480225,\n",
       "     'Y': 0.3790191411972046},\n",
       "    {'Type': 'midJawlineLeft',\n",
       "     'X': 0.46925732493400574,\n",
       "     'Y': 0.5107712745666504},\n",
       "    {'Type': 'chinBottom', 'X': 0.5275542736053467, 'Y': 0.5681797862052917},\n",
       "    {'Type': 'midJawlineRight',\n",
       "     'X': 0.5856822729110718,\n",
       "     'Y': 0.49999287724494934},\n",
       "    {'Type': 'upperJawlineRight',\n",
       "     'X': 0.5959899425506592,\n",
       "     'Y': 0.36556994915008545}],\n",
       "   'Pose': {'Roll': -4.344897270202637,\n",
       "    'Yaw': -0.6061569452285767,\n",
       "    'Pitch': 12.328144073486328},\n",
       "   'Quality': {'Brightness': 65.27978515625, 'Sharpness': 83.14741516113281},\n",
       "   'Confidence': 99.99980926513672,\n",
       "   'FaceOccluded': {'Value': False, 'Confidence': 99.84680938720703},\n",
       "   'EyeDirection': {'Yaw': -6.648810386657715,\n",
       "    'Pitch': -12.662519454956055,\n",
       "    'Confidence': 99.9830322265625}}],\n",
       " 'ResponseMetadata': {'RequestId': 'afa0a721-7feb-4862-9158-47aaddaac639',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'afa0a721-7feb-4862-9158-47aaddaac639',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3499',\n",
       "   'date': 'Thu, 12 Dec 2024 18:01:04 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(detect_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display number of faces detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of faces detected: {}\".format(len(detect_faces_response['FaceDetails'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize faces in video\n",
    "Face recognition in video is an async operation. \n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/faces-sqs-video.html. \n",
    "\n",
    "- First we start a face detection job which returns a Job Id.\n",
    "- We can then call `get_face_detection` to get the job status and after job is complete, we can get object metadata.\n",
    "- In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show video in the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td style='vertical-align: top'><video controls='controls' autoplay width='640' height='360' name='Video' src='https://test-images-891377001208.s3.amazonaws.com/leaving.mp4?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=5APls18is5B5kevaBGlwDD22vhU%3D&Expires=1734030078'></video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_name = \"leaving.mp4\"\n",
    "s3_video_url = s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': video_name})\n",
    "\n",
    "video_tag = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(s3_video_url)\n",
    "video_ui = \"<table><tr><td style='vertical-align: top'>{}</td></tr></table>\".format(video_tag)\n",
    "display(HTML(video_ui))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to start a job for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Id: 0db2ec3f95cc58b2522f563728bfde5a5122bcd30ce8a1d51bb1347575acbe0f'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_face_detection = rekognition.start_face_detection(\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': video_name,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "faces_job_id = start_face_detection['JobId']\n",
    "display(\"Job Id: {0}\".format(faces_job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional (Optional) Request Attributes\n",
    "\n",
    "ClientRequestToken, JobTag, MinConfidence, and NotificationChannel:\n",
    "https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartFaceDetection.html\n",
    "\n",
    "FaceDetail:\n",
    "https://docs.aws.amazon.com/rekognition/latest/APIReference/API_FaceDetail.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for object detection job to complete\n",
    "\n",
    "In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCEEDED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_face_detection = rekognition.get_face_detection(\n",
    "    JobId=faces_job_id\n",
    ")\n",
    "\n",
    "while(get_face_detection['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    " \n",
    "    get_face_detection = rekognition.get_face_detection(\n",
    "        JobId=faces_job_id)\n",
    "    \n",
    "display(get_face_detection['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see list of detected faces and attributes.\n",
    "For each detected face, you will see information like Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(get_face_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display face detected by timestamp and alert when faces are not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face on Timestamp: 0 with confidence: 99.9998779296875\n",
      "Detected face on Timestamp: 467 with confidence: 99.99989318847656\n",
      "Detected face on Timestamp: 967 with confidence: 99.9998550415039\n",
      "Detected face on Timestamp: 1468 with confidence: 99.99980926513672\n",
      "Detected face on Timestamp: 1968 with confidence: 99.97500610351562\n",
      "ALERT - no face detected for 5.506 seconds\n",
      "Detected face on Timestamp: 7474 with confidence: 99.94216918945312\n",
      "Detected face on Timestamp: 7974 with confidence: 99.9998779296875\n"
     ]
    }
   ],
   "source": [
    "# Faces detected in each frame\n",
    "prev_ts = 0\n",
    "threshold = 1000 # ms\n",
    "for face in get_face_detection['Faces']:\n",
    "    ts = face[\"Timestamp\"]\n",
    "    cconfidence = face[\"Face\"][\"Confidence\"]\n",
    "    if ts-prev_ts>threshold:\n",
    "        print(\"ALERT - no face detected for {} seconds\".format((ts-prev_ts)/1000))\n",
    "    print(\"Detected face on Timestamp: {} with confidence: {}\".format(ts, cconfidence))\n",
    "    prev_ts = ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartFaceDetection.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_GetFaceDetection.html\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully used Amazon Rekognition to detect faces in images and videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
