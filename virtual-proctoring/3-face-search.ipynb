{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face search using Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [compare faces API]( https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CompareFaces.html) and [face search API](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_SearchFaces.html) in Amazon Rekognition to detect known faces.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize dependencies\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "import time\n",
    "\n",
    "# Initialize clients\n",
    "REGION = boto3.session.Session().region_name or 'us-east-1'\n",
    "rekognition = boto3.client('rekognition', REGION)\n",
    "s3 = boto3.client('s3', REGION)\n",
    "\n",
    "bucket_name = 'test-images-891377001208'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect known faces in image\n",
    "\n",
    "There are two main ways to detect known faces by using Amazon Rekognition.\n",
    "\n",
    "\n",
    "1. The first is by using [the compare faces API](https://docs.aws.amazon.com/rekognition/latest/dg/faces-comparefaces.html) to compare two images.\n",
    "2. The second is by creating a collection of known images using the [index faces API and then using the search faces API](https://docs.aws.amazon.com/rekognition/latest/dg/collections.html) to detect all the faces belonging to a particular collection on an image or video.\n",
    "***\n",
    "\n",
    "### 1. Call Rekognition to compare two faces\n",
    "\n",
    "<https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CompareFaces.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://test-images-891377001208.s3.amazonaws.com/identity.jpg?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=bis%2FWUyQiDcsw26iejAJ%2Fdp0z9Q%3D&Expires=1734030199\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://test-images-891377001208.s3.amazonaws.com/looking_at_screen.jpg?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=ZiDMXD%2FF46LsHUPwfNNImHRfIPs%3D&Expires=1734030199\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show images\n",
    "source = \"identity.jpg\" # image profile\n",
    "target = \"looking_at_screen.jpg\" # screenshot\n",
    "\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': source})))\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': target})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_faces_response = rekognition.compare_faces(\n",
    "    SourceImage={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': source\n",
    "        }\n",
    "    },\n",
    "    TargetImage={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': target\n",
    "        }        \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see detected faces, confidence score and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Faces: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SourceImageFace': {'BoundingBox': {'Width': 0.4096868336200714,\n",
       "   'Height': 0.40416184067726135,\n",
       "   'Left': 0.2767603099346161,\n",
       "   'Top': 0.1920318752527237},\n",
       "  'Confidence': 99.99990844726562},\n",
       " 'FaceMatches': [{'Similarity': 99.9990005493164,\n",
       "   'Face': {'BoundingBox': {'Width': 0.1543322205543518,\n",
       "     'Height': 0.38393434882164,\n",
       "     'Left': 0.44668450951576233,\n",
       "     'Top': 0.20054830610752106},\n",
       "    'Confidence': 99.99980926513672,\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4895631968975067,\n",
       "      'Y': 0.35889360308647156},\n",
       "     {'Type': 'eyeRight', 'X': 0.5552297830581665, 'Y': 0.3527182638645172},\n",
       "     {'Type': 'mouthLeft', 'X': 0.49813297390937805, 'Y': 0.48312491178512573},\n",
       "     {'Type': 'mouthRight', 'X': 0.5526813268661499, 'Y': 0.47797098755836487},\n",
       "     {'Type': 'nose', 'X': 0.5225225687026978, 'Y': 0.41206860542297363}],\n",
       "    'Pose': {'Roll': -4.344897270202637,\n",
       "     'Yaw': -0.6061569452285767,\n",
       "     'Pitch': 12.328144073486328},\n",
       "    'Quality': {'Brightness': 65.27978515625,\n",
       "     'Sharpness': 83.14741516113281}}}],\n",
       " 'UnmatchedFaces': [],\n",
       " 'ResponseMetadata': {'RequestId': 'f3dda4db-16dc-4b36-82e7-802fdebb7b0d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f3dda4db-16dc-4b36-82e7-802fdebb7b0d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '910',\n",
       "   'date': 'Thu, 12 Dec 2024 18:03:25 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Matched Faces: {}\".format(len(compare_faces_response['FaceMatches'])))\n",
    "display(compare_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Index Faces and Search Faces\n",
    "\n",
    "Now let's detect faces using the Search functionality. \n",
    "\n",
    "#### Call Rekognition to create a new collection\n",
    "\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/create-collection-procedure.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created\n"
     ]
    }
   ],
   "source": [
    "collection_id = bucket_name\n",
    "\n",
    "# Create collection unless it already exsists\n",
    "try:\n",
    "    rekognition.describe_collection(CollectionId=collection_id)\n",
    "    print(\"Collection already exists\")\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    rekognition.create_collection(CollectionId=collection_id)\n",
    "    print(\"Collection created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://test-images-891377001208.s3.amazonaws.com/looking_at_screen.jpg?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=weqeukyypIu5GYCQdozpzZAOyNQ%3D&Expires=1734030219\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show image\n",
    "image_name = \"looking_at_screen.jpg\"\n",
    "display(IImage(url=s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': image_name})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to search faces in the collection\n",
    "\n",
    "By making this call, unsurpsingly we'll get no matches the first time, because no image has been indexed yet.\n",
    "\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/search-face-with-image-procedure.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_faces_response = rekognition.search_faces_by_image(\n",
    "    CollectionId=collection_id,\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': image_name,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see detected faces, confidence score and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Faces: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SearchedFaceBoundingBox': {'Width': 0.1543322205543518,\n",
       "  'Height': 0.38393434882164,\n",
       "  'Left': 0.44668450951576233,\n",
       "  'Top': 0.20054830610752106},\n",
       " 'SearchedFaceConfidence': 99.99980926513672,\n",
       " 'FaceMatches': [],\n",
       " 'FaceModelVersion': '7.0',\n",
       " 'ResponseMetadata': {'RequestId': 'f3a3eb87-9a20-478b-b457-91bbda8911ec',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f3a3eb87-9a20-478b-b457-91bbda8911ec',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '220',\n",
       "   'date': 'Thu, 12 Dec 2024 18:03:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Matched Faces: {}\".format(len(search_faces_response['FaceMatches'])))\n",
    "display(search_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Face in the Collection\n",
    "\n",
    "Now let's call Amazon Rekognition to create a new identity for the given collection.\n",
    "<https://docs.aws.amazon.com/rekognition/latest/APIReference/API_IndexFaces.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_faces_response = rekognition.index_faces(\n",
    "    CollectionId=collection_id,\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': 'identity.jpg',\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see an ID identifying the newly created identity called FaceId.\n",
    "You can persist that ID in a Database and associate it with a Name for a future lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FaceRecords': [{'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "    'BoundingBox': {'Width': 0.4096868336200714,\n",
       "     'Height': 0.40416184067726135,\n",
       "     'Left': 0.2767603099346161,\n",
       "     'Top': 0.1920318752527237},\n",
       "    'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "    'Confidence': 99.99990844726562},\n",
       "   'FaceDetail': {'BoundingBox': {'Width': 0.4096868336200714,\n",
       "     'Height': 0.40416184067726135,\n",
       "     'Left': 0.2767603099346161,\n",
       "     'Top': 0.1920318752527237},\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.38909125328063965,\n",
       "      'Y': 0.35645154118537903},\n",
       "     {'Type': 'eyeRight', 'X': 0.5686460137367249, 'Y': 0.3490675687789917},\n",
       "     {'Type': 'mouthLeft', 'X': 0.41466090083122253, 'Y': 0.4943619668483734},\n",
       "     {'Type': 'mouthRight', 'X': 0.5641433000564575, 'Y': 0.4880884885787964},\n",
       "     {'Type': 'nose', 'X': 0.4862532615661621, 'Y': 0.41749873757362366}],\n",
       "    'Pose': {'Roll': -2.4268858432769775,\n",
       "     'Yaw': 0.20838695764541626,\n",
       "     'Pitch': 10.606622695922852},\n",
       "    'Quality': {'Brightness': 92.93070220947266,\n",
       "     'Sharpness': 94.08262634277344},\n",
       "    'Confidence': 99.99990844726562}}],\n",
       " 'FaceModelVersion': '7.0',\n",
       " 'UnindexedFaces': [],\n",
       " 'ResponseMetadata': {'RequestId': 'de4d49f1-7b58-45f1-8003-68ef4aa35a8a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'de4d49f1-7b58-45f1-8003-68ef4aa35a8a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1001',\n",
       "   'date': 'Thu, 12 Dec 2024 18:03:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "identities = {}\n",
    "identities[index_faces_response['FaceRecords'][0]['Face']['FaceId']] = 'John Doe'\n",
    "display(index_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition again to search faces in the collection\n",
    "\n",
    "This time, the search should match the indexed identity.\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/search-face-with-image-procedure.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_faces_response = rekognition.search_faces_by_image(\n",
    "    CollectionId=collection_id,\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': image_name,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see detected faces, confidence score and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Faces: 1\n",
      "Detected John Doe with Confidence: 99.9999008178711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SearchedFaceBoundingBox': {'Width': 0.1543322205543518,\n",
       "  'Height': 0.38393434882164,\n",
       "  'Left': 0.44668450951576233,\n",
       "  'Top': 0.20054830610752106},\n",
       " 'SearchedFaceConfidence': 99.99980926513672,\n",
       " 'FaceMatches': [{'Similarity': 99.9990005493164,\n",
       "   'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "    'BoundingBox': {'Width': 0.40968701243400574,\n",
       "     'Height': 0.4041619896888733,\n",
       "     'Left': 0.2767600119113922,\n",
       "     'Top': 0.19203199446201324},\n",
       "    'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "    'Confidence': 99.9999008178711,\n",
       "    'IndexFacesModelVersion': '7.0'}}],\n",
       " 'FaceModelVersion': '7.0',\n",
       " 'ResponseMetadata': {'RequestId': '78860856-b7fb-4788-ad5c-7e32dce7cfee',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '78860856-b7fb-4788-ad5c-7e32dce7cfee',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '542',\n",
       "   'date': 'Thu, 12 Dec 2024 18:04:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Matched Faces: {}\".format(len(search_faces_response['FaceMatches'])))\n",
    "for match in search_faces_response['FaceMatches']:\n",
    "    print(\"Detected {} with Confidence: {}\".format(identities[match['Face']['FaceId']], match['Face']['Confidence']))\n",
    "\n",
    "display(search_faces_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search faces in video\n",
    "Search recognition in video is an async operation. \n",
    "https://docs.aws.amazon.com/rekognition/latest/dg/procedure-person-search-videos.html. \n",
    "\n",
    "- First we start a search detection job which returns a Job Id.\n",
    "- We can then call `get_search_detection` to get the job status and after job is complete, we can get face metadata.\n",
    "- In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"leaving.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show video in the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td style='vertical-align: top'><video controls='controls' autoplay width='640' height='360' name='Video' src='https://test-images-891377001208.s3.amazonaws.com/leaving.mp4?AWSAccessKeyId=AKIA47CRVUL4K7TWNMX5&Signature=z4iW48nN%2BTIOghPlsVah%2FAztEYE%3D&Expires=1734030253'></video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_video_url = s3.generate_presigned_url('get_object', Params={'Bucket': bucket_name, 'Key': video_name})\n",
    "\n",
    "video_tag = \"<video controls='controls' autoplay width='640' height='360' name='Video' src='{0}'></video>\".format(s3_video_url)\n",
    "video_ui = \"<table><tr><td style='vertical-align: top'>{}</td></tr></table>\".format(video_tag)\n",
    "display(HTML(video_ui))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to start a job for face search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Id: d3c9e426aeedf4281e8afcc34920204466ea145d1b48fc4a8a45f1dd591f10f4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_search_detection = rekognition.start_face_search(\n",
    "    CollectionId=collection_id,\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': bucket_name,\n",
    "            'Name': video_name,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "search_job_id = start_search_detection['JobId']\n",
    "display(\"Job Id: {0}\".format(search_job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional (Optional) Request Attributes\n",
    "\n",
    "ClientRequestToken, FaceMatchThreshold, JobTag, NotificationChannel:\n",
    "https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartFaceSearch.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for object detection job to complete\n",
    "\n",
    "In production use cases, you would usually use StepFunction or SNS topic to get notified when job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCEEDED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_search_detection = rekognition.get_face_search(\n",
    "    JobId=search_job_id\n",
    ")\n",
    "\n",
    "while(get_search_detection['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    " \n",
    "    get_search_detection = rekognition.get_face_search(\n",
    "        JobId=search_job_id)\n",
    "    \n",
    "display(get_search_detection['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review raw JSON reponse from Rekognition\n",
    "\n",
    "In the JSON response below, you will see list of detected faces and attributes.\n",
    "For each detected face, you will see information like Timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JobStatus': 'SUCCEEDED',\n",
       " 'VideoMetadata': {'Codec': 'h264',\n",
       "  'DurationMillis': 8274,\n",
       "  'Format': 'QuickTime / MOV',\n",
       "  'FrameRate': 29.970029830932617,\n",
       "  'FrameHeight': 720,\n",
       "  'FrameWidth': 1280,\n",
       "  'ColorRange': 'LIMITED'},\n",
       " 'Persons': [{'Timestamp': 0,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.16818752884864807,\n",
       "      'Height': 0.4147394895553589,\n",
       "      'Left': 0.4027940630912781,\n",
       "      'Top': 0.19215774536132812},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.44816869497299194,\n",
       "       'Y': 0.3532431721687317},\n",
       "      {'Type': 'eyeRight', 'X': 0.5202697515487671, 'Y': 0.3480505347251892},\n",
       "      {'Type': 'mouthLeft', 'X': 0.4570233225822449, 'Y': 0.4924316704273224},\n",
       "      {'Type': 'mouthRight', 'X': 0.516939103603363, 'Y': 0.4880813956260681},\n",
       "      {'Type': 'nose', 'X': 0.4849218726158142, 'Y': 0.4130924344062805}],\n",
       "     'Pose': {'Roll': -3.3523330688476562,\n",
       "      'Yaw': -1.0463366508483887,\n",
       "      'Pitch': 11.794028282165527},\n",
       "     'Quality': {'Brightness': 61.341087341308594,\n",
       "      'Sharpness': 78.64350128173828},\n",
       "     'Confidence': 99.9998779296875}},\n",
       "   'FaceMatches': [{'Similarity': 99.99881744384766,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 467,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.16745023429393768,\n",
       "      'Height': 0.4183101952075958,\n",
       "      'Left': 0.4033903479576111,\n",
       "      'Top': 0.19120857119560242},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.44807857275009155,\n",
       "       'Y': 0.35309037566185},\n",
       "      {'Type': 'eyeRight', 'X': 0.5202995538711548, 'Y': 0.3474563956260681},\n",
       "      {'Type': 'mouthLeft', 'X': 0.4571771025657654, 'Y': 0.49334004521369934},\n",
       "      {'Type': 'mouthRight',\n",
       "       'X': 0.5171834230422974,\n",
       "       'Y': 0.48864516615867615},\n",
       "      {'Type': 'nose', 'X': 0.4845770001411438, 'Y': 0.4127848744392395}],\n",
       "     'Pose': {'Roll': -3.5783164501190186,\n",
       "      'Yaw': -1.2137315273284912,\n",
       "      'Pitch': 11.889404296875},\n",
       "     'Quality': {'Brightness': 62.08224868774414,\n",
       "      'Sharpness': 78.64350128173828},\n",
       "     'Confidence': 99.99989318847656}},\n",
       "   'FaceMatches': [{'Similarity': 99.99913787841797,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 967,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.16692256927490234,\n",
       "      'Height': 0.4184645712375641,\n",
       "      'Left': 0.4053696095943451,\n",
       "      'Top': 0.18838517367839813},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.45003432035446167,\n",
       "       'Y': 0.34781959652900696},\n",
       "      {'Type': 'eyeRight', 'X': 0.5219027400016785, 'Y': 0.34199947118759155},\n",
       "      {'Type': 'mouthLeft',\n",
       "       'X': 0.45946574211120605,\n",
       "       'Y': 0.48849037289619446},\n",
       "      {'Type': 'mouthRight', 'X': 0.519174337387085, 'Y': 0.48366689682006836},\n",
       "      {'Type': 'nose', 'X': 0.48652204871177673, 'Y': 0.4065985679626465}],\n",
       "     'Pose': {'Roll': -3.4498047828674316,\n",
       "      'Yaw': -1.1248937845230103,\n",
       "      'Pitch': 12.3969087600708},\n",
       "     'Quality': {'Brightness': 62.19028091430664,\n",
       "      'Sharpness': 83.14741516113281},\n",
       "     'Confidence': 99.9998550415039}},\n",
       "   'FaceMatches': [{'Similarity': 99.99920654296875,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 1468,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.17073383927345276,\n",
       "      'Height': 0.4249378740787506,\n",
       "      'Left': 0.4162800908088684,\n",
       "      'Top': 0.17720438539981842},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.46128320693969727,\n",
       "       'Y': 0.34284815192222595},\n",
       "      {'Type': 'eyeRight', 'X': 0.5351775288581848, 'Y': 0.3382164537906647},\n",
       "      {'Type': 'mouthLeft', 'X': 0.4700540006160736, 'Y': 0.48785459995269775},\n",
       "      {'Type': 'mouthRight', 'X': 0.5314054489135742, 'Y': 0.4839097261428833},\n",
       "      {'Type': 'nose', 'X': 0.4990372061729431, 'Y': 0.4041976034641266}],\n",
       "     'Pose': {'Roll': -3.011322021484375,\n",
       "      'Yaw': -0.5902771949768066,\n",
       "      'Pitch': 13.133792877197266},\n",
       "     'Quality': {'Brightness': 62.67502975463867,\n",
       "      'Sharpness': 83.14741516113281},\n",
       "     'Confidence': 99.99980926513672}},\n",
       "   'FaceMatches': [{'Similarity': 99.9987564086914,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 1968,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.2242431640625,\n",
       "      'Height': 0.44468551874160767,\n",
       "      'Left': 0.4172670245170593,\n",
       "      'Top': -0.015209536999464035},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.4850693345069885,\n",
       "       'Y': 0.016073234379291534},\n",
       "      {'Type': 'eyeRight', 'X': 0.5752243399620056, 'Y': 0.010495321825146675},\n",
       "      {'Type': 'mouthLeft', 'X': 0.49676966667175293, 'Y': 0.2473260462284088},\n",
       "      {'Type': 'mouthRight',\n",
       "       'X': 0.5718590021133423,\n",
       "       'Y': 0.24248328804969788},\n",
       "      {'Type': 'nose', 'X': 0.5338179469108582, 'Y': 0.10964689403772354}],\n",
       "     'Pose': {'Roll': -0.40264278650283813,\n",
       "      'Yaw': 2.976609945297241,\n",
       "      'Pitch': 6.90738582611084},\n",
       "     'Quality': {'Brightness': 54.57080078125, 'Sharpness': 46.02980041503906},\n",
       "     'Confidence': 99.97500610351562}},\n",
       "   'FaceMatches': [{'Similarity': 99.2385025024414,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 7474,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.2564225196838379,\n",
       "      'Height': 0.44742992520332336,\n",
       "      'Left': 0.3853681981563568,\n",
       "      'Top': -0.013277816586196423},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.4599141478538513,\n",
       "       'Y': 0.0477689728140831},\n",
       "      {'Type': 'eyeRight', 'X': 0.5382977724075317, 'Y': 0.042889587581157684},\n",
       "      {'Type': 'mouthLeft', 'X': 0.4705100953578949, 'Y': 0.25930023193359375},\n",
       "      {'Type': 'mouthRight', 'X': 0.5362094640731812, 'Y': 0.2554461658000946},\n",
       "      {'Type': 'nose', 'X': 0.49351435899734497, 'Y': 0.1463490128517151}],\n",
       "     'Pose': {'Roll': 1.9751272201538086,\n",
       "      'Yaw': -1.0825393199920654,\n",
       "      'Pitch': -5.494706630706787},\n",
       "     'Quality': {'Brightness': 67.92471313476562,\n",
       "      'Sharpness': 32.20803451538086},\n",
       "     'Confidence': 99.94216918945312}},\n",
       "   'FaceMatches': [{'Similarity': 94.17875671386719,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]},\n",
       "  {'Timestamp': 7974,\n",
       "   'Person': {'Index': 0,\n",
       "    'Face': {'BoundingBox': {'Width': 0.1664430797100067,\n",
       "      'Height': 0.40475451946258545,\n",
       "      'Left': 0.3996661305427551,\n",
       "      'Top': 0.24407462775707245},\n",
       "     'Landmarks': [{'Type': 'eyeLeft',\n",
       "       'X': 0.44527143239974976,\n",
       "       'Y': 0.40504756569862366},\n",
       "      {'Type': 'eyeRight', 'X': 0.516864538192749, 'Y': 0.4020148813724518},\n",
       "      {'Type': 'mouthLeft', 'X': 0.45325106382369995, 'Y': 0.5415371060371399},\n",
       "      {'Type': 'mouthRight', 'X': 0.5127215385437012, 'Y': 0.5389413833618164},\n",
       "      {'Type': 'nose', 'X': 0.4817923605442047, 'Y': 0.4639992117881775}],\n",
       "     'Pose': {'Roll': -1.9057469367980957,\n",
       "      'Yaw': -0.5593836903572083,\n",
       "      'Pitch': 12.691267967224121},\n",
       "     'Quality': {'Brightness': 62.83448791503906,\n",
       "      'Sharpness': 73.32209777832031},\n",
       "     'Confidence': 99.9998779296875}},\n",
       "   'FaceMatches': [{'Similarity': 99.99934387207031,\n",
       "     'Face': {'FaceId': '17b14ca4-916f-4d68-b7a5-9de7155f6ebe',\n",
       "      'BoundingBox': {'Width': 0.40968701243400574,\n",
       "       'Height': 0.4041619896888733,\n",
       "       'Left': 0.2767600119113922,\n",
       "       'Top': 0.19203199446201324},\n",
       "      'ImageId': 'a112d078-7e86-3fd0-bd81-cbe3c3a825af',\n",
       "      'Confidence': 99.9999008178711}}]}],\n",
       " 'JobId': 'd3c9e426aeedf4281e8afcc34920204466ea145d1b48fc4a8a45f1dd591f10f4',\n",
       " 'Video': {'S3Object': {'Bucket': 'test-images-891377001208',\n",
       "   'Name': 'leaving.mp4'}},\n",
       " 'ResponseMetadata': {'RequestId': 'eec8292d-eb79-404b-a21e-3e9b99d803e7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'eec8292d-eb79-404b-a21e-3e9b99d803e7',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '7485',\n",
       "   'date': 'Thu, 12 Dec 2024 18:04:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_search_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display face detected by timestamp and alert when faces are not detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected John Doe on Timestamp: 0 with confidence: 99.9999008178711\n",
      "Detected John Doe on Timestamp: 467 with confidence: 99.9999008178711\n",
      "Detected John Doe on Timestamp: 967 with confidence: 99.9999008178711\n",
      "Detected John Doe on Timestamp: 1468 with confidence: 99.9999008178711\n",
      "Detected John Doe on Timestamp: 1968 with confidence: 99.9999008178711\n",
      "ALERT - no face matched for 5.506 seconds\n",
      "Detected John Doe on Timestamp: 7474 with confidence: 99.9999008178711\n",
      "Detected John Doe on Timestamp: 7974 with confidence: 99.9999008178711\n"
     ]
    }
   ],
   "source": [
    "# Faces detected in each frame\n",
    "prev_ts = 0\n",
    "threshold = 1000 # ms\n",
    "for person in get_search_detection['Persons']:\n",
    "    ts = person[\"Timestamp\"]\n",
    "    if ts-prev_ts>threshold:\n",
    "        print(\"ALERT - no face matched for {} seconds\".format((ts-prev_ts)/1000))\n",
    "    for match in person[\"FaceMatches\"]:\n",
    "        confidence = match[\"Face\"][\"Confidence\"]\n",
    "        identity = identities[match[\"Face\"][\"FaceId\"]]\n",
    "        print(\"Detected {} on Timestamp: {} with confidence: {}\".format(identity, ts, confidence))\n",
    "    prev_ts = ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup resources\n",
    "\n",
    "Let's call Rekognition to delete the Collection.\n",
    "<https://docs.aws.amazon.com/rekognition/latest/dg/delete-collection-procedure.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition.delete_collection(CollectionId=collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CreateCollection.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_IndexFaces.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_SearchFaces.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartFaceSearch.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_GetLabelDetection.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/APIReference/API_GetFaceSearch.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully used Amazon Rekognition to search for known faces in images and videos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
